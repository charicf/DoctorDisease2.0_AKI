{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "krvFKCrgzNBg",
      "metadata": {
        "id": "krvFKCrgzNBg"
      },
      "outputs": [],
      "source": [
        "#import python and pytorch libraries\n",
        "from __future__ import absolute_import\n",
        "from __future__ import print_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "VpfRprdyzNBk",
      "metadata": {
        "id": "VpfRprdyzNBk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import codecs\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import logging\n",
        "import tempfile\n",
        "import shutil\n",
        "import pickle\n",
        "import platform\n",
        "import json\n",
        "from datetime import datetime\n",
        "import random\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import collections\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a95de6f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install import_ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8ymHO3MQzNBl",
      "metadata": {
        "id": "8ymHO3MQzNBl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from mimic_utils_text.ipynb\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\DAIMA Researcher\\anaconda3\\Lib\\site-packages\\nbformat\\__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
            "  validate(nb)\n"
          ]
        }
      ],
      "source": [
        "import import_ipynb\n",
        "from mimic_utils_text import InHospitalMortalityReader, Discretizer, Normalizer, read_chunk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S8CvNUIozNBm",
      "metadata": {
        "id": "S8CvNUIozNBm"
      },
      "source": [
        "# Pytorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Kye4BRKkzNBo",
      "metadata": {
        "id": "Kye4BRKkzNBo"
      },
      "outputs": [],
      "source": [
        "# pad missing values in the nested lists with 0s\n",
        "def pad_missing_value_with_zero(data):\n",
        "    a1 = np.zeros((len(data), max([len(k) for k in data]), 35))\n",
        "    for ctr,k in enumerate(data):\n",
        "        a1[ctr,:len(k),:] = k\n",
        "    return a1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "k7OAWgJ5zNBo",
      "metadata": {
        "id": "k7OAWgJ5zNBo"
      },
      "outputs": [],
      "source": [
        "# pytroch class for reading data into batches\n",
        "class MIMICDataset(Dataset):\n",
        "    \"\"\"\n",
        "       Loads time series data into memory from a text file,\n",
        "       split by newlines. \n",
        "    \"\"\"\n",
        "    def __init__(self, reader, target_repl=False, batch_labels=False):\n",
        "        self.data = []\n",
        "        self.y  = []\n",
        "        N = reader.get_number_of_examples()\n",
        "        print(N)\n",
        "        # read data form cvs files\n",
        "        ret = read_chunk(reader, N)\n",
        "        # read into memory structured data X and labels y\n",
        "        data = ret[\"X\"]\n",
        "        ts = ret[\"t\"]\n",
        "        labels = ret[\"y\"]\n",
        "        names = ret[\"name\"]\n",
        "        \n",
        "        # pad missing values in the list of arrays with 0s\n",
        "        data = pad_missing_value_with_zero(data)\n",
        "        \n",
        "        self.data = np.array(data, dtype=np.float32) \n",
        "        self.T = self.data.shape[1]\n",
        "\n",
        "        if batch_labels:\n",
        "            self.y = np.array([[l] for l in labels], dtype=np.float32)\n",
        "        else:\n",
        "            self.y = np.array(labels, dtype=np.float32)\n",
        "        if target_repl:\n",
        "            self.y = self._extend_labels(self.y)\n",
        "\n",
        "    def _extend_labels(self, labels):\n",
        "        # (B,)\n",
        "        labels = labels.repeat(self.T, axis=1)  # (B, T)\n",
        "        return labels\n",
        "\n",
        "    def __len__(self):\n",
        "        # overide len to get number of instances\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get features (physiological variables x) and label for a given instance index\n",
        "        return self.data[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WEU3xsjYzNBp",
      "metadata": {
        "id": "WEU3xsjYzNBp"
      },
      "source": [
        "# Evaluation metrics\n",
        "The main measure used are accuracy, ROC AUC and PR AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3-4bqPhpzNBq",
      "metadata": {
        "id": "3-4bqPhpzNBq"
      },
      "outputs": [],
      "source": [
        "# eval metrics\n",
        "def print_metrics_binary(y_true, predictions, logging, verbose=1):\n",
        "    predictions = np.array(predictions)\n",
        "    if len(predictions.shape) == 1:\n",
        "        predictions = np.stack([1 - predictions, predictions]).transpose((1, 0))\n",
        "    cf = metrics.confusion_matrix(y_true, predictions.argmax(axis=1))\n",
        "    if verbose:\n",
        "        logging.info(\"confusion matrix:\")\n",
        "        logging.info(cf)\n",
        "    cf = cf.astype(np.float32)\n",
        "\n",
        "    acc = (cf[0][0] + cf[1][1]) / np.sum(cf)\n",
        "    prec0 = cf[0][0] / (cf[0][0] + cf[1][0])\n",
        "    prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
        "    rec0 = cf[0][0] / (cf[0][0] + cf[0][1])\n",
        "    rec1 = cf[1][1] / (cf[1][1] + cf[1][0])\n",
        "    auroc = metrics.roc_auc_score(y_true, predictions[:, 1])\n",
        "\n",
        "    (precisions, recalls, thresholds) = metrics.precision_recall_curve(y_true, predictions[:, 1])\n",
        "    auprc = metrics.auc(recalls, precisions)\n",
        "    minpse = np.max([min(x, y) for (x, y) in zip(precisions, recalls)])\n",
        "\n",
        "    if verbose:\n",
        "        logging.info(\"accuracy = {0:.3f}\".format(acc))\n",
        "        logging.info(\"precision class 0 = {0:.3f}\".format(prec0))\n",
        "        logging.info(\"precision class 1 = {0:.3f}\".format(prec1))\n",
        "        logging.info(\"recall class 0 = {0:.3f}\".format(rec0))\n",
        "        logging.info(\"recall class 1 = {0:.3f}\".format(rec1))\n",
        "        logging.info(\"AUC of ROC = {0:.3f}\".format(auroc))\n",
        "        logging.info(\"AUC of PRC = {0:.3f}\".format(auprc))\n",
        "       \n",
        "\n",
        "    return {\"acc\": acc,\n",
        "            \"prec0\": prec0,\n",
        "            \"prec1\": prec1,\n",
        "            \"rec0\": rec0,\n",
        "            \"rec1\": rec1,\n",
        "            \"auroc\": auroc,\n",
        "            \"auprc\": auprc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2iR32scTzNBs",
      "metadata": {
        "id": "2iR32scTzNBs"
      },
      "outputs": [],
      "source": [
        "def performance_with_cutoff (y_test, pred_probabilities, verbose=1):\n",
        "    # performance\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_probabilities)\n",
        "    # compute roc auc\n",
        "    roc_auc = metrics.roc_auc_score(y_test, pred_probabilities, average = 'micro')\n",
        "    # compute Precision_Recall curves\n",
        "    precision, recall, _ = metrics.precision_recall_curve(y_test, pred_probabilities)\n",
        "    # compute PR_AUC\n",
        "    pr_auc = metrics.auc(recall, precision)\n",
        "       \n",
        "    # compute confusion matrix\n",
        "    optimal_cut_off = round(thresholds[np.argmax(tpr - fpr)],4)\n",
        "    a = np.where(pred_probabilities > optimal_cut_off, 1, 0)\n",
        "    brier = round(metrics.brier_score_loss(y_test, pred_probabilities, sample_weight=None, pos_label=None),3)\n",
        "    predictions = np.where(pred_probabilities > optimal_cut_off, 1, 0)  \n",
        "    matrix = metrics.confusion_matrix(y_test, a, labels=None, normalize=None)\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"confusion matrix after tuning with cutoff\")\n",
        "        print('Cut off: ' + str(optimal_cut_off))\n",
        "        print(matrix)\n",
        "        print(\"accuracy with cutoff = {0:.3f}\".format(metrics.accuracy_score(y_test, predictions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lRnrEs6tzNBs",
      "metadata": {
        "id": "lRnrEs6tzNBs"
      },
      "source": [
        "# Training\n",
        "Here we define the model, loss and training loop. The model is an LSTM. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "pFN1rYKRzNBt",
      "metadata": {
        "id": "pFN1rYKRzNBt"
      },
      "outputs": [],
      "source": [
        "#model\n",
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_size, hidden_size, feat_size, emb_size,\n",
        "                 bidirectional=False, dropout=0.2, aggregation_type='last_state'):\n",
        "        \"\"\"\n",
        "        constructor, here we define the hidden layers for our architecture       \n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # define if the rnn will be bidirectional\n",
        "        self.bidirectional = bidirectional\n",
        "        # define the aggregation type of the features for the classifier for example, you can take the mean\n",
        "        self.aggregation_type = aggregation_type\n",
        "        self.encoder = nn.Linear(feat_size, emb_size, bias=True)\n",
        "        # Create a (bidirectional) LSTM to encode sequence\n",
        "        self.lstm = nn.LSTM(emb_size, hidden_size, batch_first=True, \n",
        "                            bidirectional=bidirectional)\n",
        "        \n",
        "        # The output of the LSTM doubles if we use a bidirectional encoder.\n",
        "        encoding_size = hidden_size * 2 if bidirectional else hidden_size\n",
        "        self.combination_layer = nn.Linear(encoding_size, encoding_size)\n",
        "        \n",
        "        # Create affine layer to project to the classes \n",
        "        self.projection = nn.Linear(encoding_size, tag_size)\n",
        "        # dropout layer for regularizetion of a sequence\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.relu = nn.ReLU()\n",
        " \n",
        "    def forward(self, x, seq_mask=None, seq_len=None):\n",
        "        # input size\n",
        "        # [B, T, feat_size] batch, time and features\n",
        "        # return unormalized probabilities (logits)\n",
        "        # the loss will compute the sigmoid and negative log-likelihood\n",
        "        #output size\n",
        "        # [B, num_class] batch, and 1 class \n",
        "        \n",
        "        #[B, T, F] batch, time, features \n",
        "        h1 = self.encoder(x)\n",
        "        h1 = self.relu(h1)\n",
        "        # [B, T, H] batch, time, hidden or hidden * 2\n",
        "        outputs, (final, _) = self.lstm(h1)\n",
        "      \n",
        "        if self.aggregation_type == 'mean':\n",
        "            # mean over hidden states of LSTM\n",
        "            outputs = self.dropout_layer(outputs)\n",
        "            h = self.relu(self.combination_layer(outputs))\n",
        "            #[B, H] batch, hidden\n",
        "            h = h.mean(dim=1) # mean over time dimension \n",
        "        elif self.aggregation_type == 'last_state': \n",
        "            # last hidden state of the lstm or concat of bidirectional forward and backward states\n",
        "            if self.bidirectional:\n",
        "                h_T_fwd = final[0] # lstm 1, last hidden state of forward lstm\n",
        "                h_T_bwd = final[1] # lstm 2. last hidden state of backward lstm\n",
        "                #[B, H*2]\n",
        "                h = torch.cat([h_T_fwd, h_T_bwd], dim=-1) # concatenate the forward with the backward in the last dimension (feat)\n",
        "            else:\n",
        "                h = final[-1]\n",
        "            h = self.relu(self.combination_layer(h))\n",
        "            h = self.dropout_layer(h)\n",
        "        #[B, H] # summary for each patient\n",
        "        #[B, 1]\n",
        "        logits = self.projection(h)\n",
        "        \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "gPdBapvazNBu",
      "metadata": {
        "id": "gPdBapvazNBu"
      },
      "outputs": [],
      "source": [
        "#eval model\n",
        "def eval_model(model, dataset, device):\n",
        "    model.eval()\n",
        "    sigmoid = nn.Sigmoid()\n",
        "    with torch.no_grad():\n",
        "        y_true = []\n",
        "        predictions = []\n",
        "        for data, labels in dataset:\n",
        "            data = data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits = model(data)\n",
        "            probs = sigmoid(logits) \n",
        "            predictions += [p.item() for p in probs]  # concatenate all predictions\n",
        "            y_true += [y.item() for y in labels]  # concatenate all labels\n",
        "    results = print_metrics_binary(y_true, predictions, logging)\n",
        "    performance_with_cutoff(y_true, predictions)\n",
        "    \n",
        "    return results, predictions, y_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "KWH1wdhLzNBu",
      "metadata": {
        "id": "KWH1wdhLzNBu"
      },
      "outputs": [],
      "source": [
        "def args_detail(args):\n",
        "    arg_detail = \"_dropout_\"+str(args['dropout'])+\",batch_size_\"+str(args['batch_size'])+ \",lr_\"+str(args['lr'])+\",epochs_\"+str(args['epochs'])\n",
        "    return arg_detail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "G8UuGBNZzNBv",
      "metadata": {
        "id": "G8UuGBNZzNBv"
      },
      "outputs": [],
      "source": [
        "def train(args):\n",
        "    mode = 'train'\n",
        "    hidden_size = args['dim']\n",
        "    dropout = args['dropout']\n",
        "    batch_size = args['batch_size']\n",
        "    learning_rate = args['lr']\n",
        "    num_epochs = args['epochs']\n",
        "    emb_size = args['emb_size']\n",
        "    aggregation_type = args['aggregation_type']\n",
        "    bidirectional_encoder = args['bidirectional'] \n",
        "    seed = args['seed']\n",
        "    steps = args['steps']\n",
        "    data = args['data']\n",
        "    notes = args['notes']\n",
        "    timestep = args['timestep']\n",
        "    normalizer_state = args['normalizer_state']\n",
        "    \n",
        "    if seed: \n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")   \n",
        "  \n",
        "    logging.basicConfig(level=logging.INFO,format='%(asctime)s %(message)s',datefmt='%Y-%m-%d %H:%M:%S', )\n",
        "    \n",
        "    # define cvs data readers\n",
        "\n",
        "    # if(notes != None):\n",
        "    train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'train'),\n",
        "                                            notes_dir=notes,\n",
        "                                            listfile=os.path.join(notes, 'train_listfile.csv'),\n",
        "                                            period_length=48.0)\n",
        "\n",
        "    val_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'train'),\n",
        "                                        notes_dir=notes,\n",
        "                                        listfile=os.path.join(notes, 'val_listfile.csv'),\n",
        "                                        period_length=48.0)\n",
        "    # else:\n",
        "    #     train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'train'),\n",
        "    #                                          notes_dir=None,\n",
        "    #                                          listfile=os.path.join(notes, 'train_listfile.csv'),\n",
        "    #                                          period_length=48.0)\n",
        "\n",
        "    #     val_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'train'),\n",
        "    #                                         notes_dir=None,\n",
        "    #                                         listfile=os.path.join(notes, 'val_listfile.csv'),\n",
        "    #                                         period_length=48.0)\n",
        "    \n",
        "\n",
        "    train_dataset = MIMICDataset(train_reader, batch_labels=True)\n",
        "    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataset = MIMICDataset(val_reader, batch_labels=True) \n",
        "    val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    #[B, T, feat_size] batch, time, and num of variables\n",
        "    feat_size = train_dataset.data.shape[-1] \n",
        "  \n",
        "    # Define the classification model\n",
        "    model = LSTMClassifier(tag_size=1, # binary\n",
        "                      feat_size= feat_size, \n",
        "                      hidden_size=hidden_size,\n",
        "                      emb_size=emb_size,\n",
        "                      bidirectional=bidirectional_encoder,\n",
        "                      dropout=dropout,\n",
        "                      aggregation_type=aggregation_type)\n",
        "\n",
        "    model = model.to(device)\n",
        "    logging.info(args)\n",
        "    logging.info(model)\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate) \n",
        "  \n",
        "    # define loss for binary classification\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # path to save model with extension .pt on disk\n",
        "    args_detail = \"_dropout_\"+str(args['dropout'])+\",batch_size_\"+str(args['batch_size'])+ \",lr_\"+str(args['lr'])+\",epochs_\"+str(args['epochs'])\n",
        "    best_val_auc = 0.\n",
        "\n",
        "    results = []\n",
        "\n",
        "    step = 0\n",
        "    num_batches = 0\n",
        "    e_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        loss_batch2 = 0.0\n",
        "        model.train()\n",
        "        for x, labels in train_dl:\n",
        "            x = x.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            y_logits = model(x)\n",
        "            loss = criterion(y_logits, labels)\n",
        "            loss_batch2 += loss.item() # keep track of loss \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            step += 1\n",
        "            num_batches += 1\n",
        "\n",
        "            # Every number of steps show the model loss\n",
        "            if step % steps == 0:\n",
        "                logging.info(\"epoch (%d) step %d: training loss = %.2f\"% (epoch, step, loss_batch2/num_batches))\n",
        "                e_losses.append(loss_batch2/num_batches)\n",
        "\n",
        "        metrics_results, _, _ = eval_model(model,\n",
        "                                val_dl,\n",
        "                                device)\n",
        "        metrics_results['epoch'] = epoch\n",
        "        # save results of current epoch\n",
        "        results.append(metrics_results)\n",
        "\n",
        "        print(metrics_results)\n",
        "\n",
        "        # Model selection \n",
        "        if metrics_results['auroc'] > best_val_auc:\n",
        "            best_val_auc = metrics_results['auroc']  \n",
        "            model_save_name2 = './saved_models/best_LSTM_mean_bi_feat'+args_detail+'.pth'\n",
        "            torch.save(model.state_dict(), model_save_name2)\n",
        "\n",
        "    model_save_name1 = './saved_models/latest_LSTM_mean_bi_feat'+args_detail+'.pth'     \n",
        "    torch.save(model.state_dict(), model_save_name1)\n",
        "\n",
        "    plt.plot(e_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sUoGos0DzNBw",
      "metadata": {
        "id": "sUoGos0DzNBw"
      },
      "outputs": [],
      "source": [
        "# execute training \n",
        "# define hyperparameters\n",
        "args = {'dim': 35,\n",
        "        'dropout': 0.2,\n",
        "        'batch_size': 64, \n",
        "        'lr': 1e-3,\n",
        "        'epochs': 20,\n",
        "        'emb_size': 35, \n",
        "        'aggregation_type': 'mean',\n",
        "        'bidirectional': True,\n",
        "        'seed':42,\n",
        "        'steps': 1000, # print loss every num of steps\n",
        "        'data':'data/AKI', # path to MIMIC data\n",
        "        'notes': 'data/AKI', # text not used in this model\n",
        "        'timestep': 1.0, # observations every hour\n",
        "        'imputation': 'previous', # imputation method\n",
        "        'normalizer_state': None} # we use normalization config\n",
        "train(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "cKL2Sv9GzNBw",
      "metadata": {
        "id": "cKL2Sv9GzNBw"
      },
      "outputs": [],
      "source": [
        "# for plot name\n",
        "args_detail = args_detail(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T7JAHhWezNBx",
      "metadata": {
        "id": "T7JAHhWezNBx"
      },
      "source": [
        "# Test\n",
        "Use the last trained model or the best validation model and run in test.\n",
        "Also use calibration curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LKLcGufrzNBx",
      "metadata": {
        "id": "LKLcGufrzNBx"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "\n",
        "def test(args):\n",
        "    # define trainning and validation datasets\n",
        "    mode = 'test'\n",
        "    hidden_size = args['dim']\n",
        "    dropout = args['dropout']\n",
        "    batch_size = args['batch_size']\n",
        "    emb_size = args['emb_size']\n",
        "    best_model = args['best_model']\n",
        "    data = args['data']\n",
        "    notes = args['notes']\n",
        "    timestep = args['timestep']\n",
        "    aggregation_type = args['aggregation_type']\n",
        "    bidirectional_encoder = args['bidirectional']\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")   \n",
        "    # 1. Get a unique working directory \n",
        "    \n",
        "    logging.basicConfig(level=logging.INFO, \n",
        "            format='%(asctime)s %(message)s', \n",
        "            datefmt='%Y-%m-%d %H:%M:%S')\n",
        "    \n",
        "\n",
        "\n",
        "    test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'test'),\n",
        "                                           notes_dir=notes,  \n",
        "                                         listfile=os.path.join(notes, 'test_listfile.csv'),\n",
        "                                         period_length=48.0)\n",
        "\n",
        "    # Read data\n",
        "    test_dataset = MIMICDataset(test_reader, batch_labels=True)\n",
        "    test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    #[B, M, feat_size]\n",
        "    feat_size = test_dataset.data.shape[-1] \n",
        "\n",
        "\n",
        "    # Define the classification model.\n",
        "    model = LSTMClassifier(tag_size=1, #binary\n",
        "                    feat_size= feat_size, \n",
        "                    hidden_size=hidden_size,\n",
        "                    emb_size=emb_size,\n",
        "                    bidirectional=bidirectional_encoder,\n",
        "                    dropout=dropout,\n",
        "                    aggregation_type=aggregation_type)\n",
        "    #load trained model from file\n",
        "    model.load_state_dict(torch.load(best_model))\n",
        "    logging.info(model)\n",
        "    model = model.to(device)\n",
        "\n",
        "    metrics_results, pred_probs, y_true = eval_model(model,\n",
        "                                test_dl,\n",
        "                                device)\n",
        "    return metrics_results, pred_probs, y_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gv00v9wgzNBy",
      "metadata": {
        "id": "gv00v9wgzNBy"
      },
      "outputs": [],
      "source": [
        "# Run test on saved model latest_classifier\n",
        "args = {'best_model':'./saved_models/latest_LSTM_mean_bi_feat'+args_detail+'.pth',\n",
        "        'dim': 35,\n",
        "        'dropout': 0.2,\n",
        "        'batch_size': 16,\n",
        "        'emb_size': 35,\n",
        "        'aggregation_type': 'mean',\n",
        "        'bidirectional': True,\n",
        "        'data':'data/AKI', # path to data\n",
        "        'notes':'data/test', # text not used in this model\n",
        "        'timestep': 1.0,\n",
        "        'imputation': 'previous',\n",
        "        'normalizer_state': None}\n",
        "print('Result of latest_classifier')        \n",
        "metrics_results, pred_probs, y_true = test(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bhtqIA0CzNBy",
      "metadata": {
        "id": "bhtqIA0CzNBy"
      },
      "outputs": [],
      "source": [
        "# Run test on saved model best_classifier\n",
        "# remember to use the same hyperparameters as in training\n",
        "args = {'best_model': './saved_models/best_LSTM_mean_bi_feat'+args_detail+'.pth',\n",
        "        'dim': 35,\n",
        "        'dropout': 0.2,\n",
        "        'batch_size': 16,\n",
        "        'emb_size': 35,\n",
        "        'aggregation_type': 'mean',\n",
        "        'bidirectional': True,\n",
        "        'data': 'data/AKI', #path to data\n",
        "        'notes': 'data/test', #the code ignores the text\n",
        "        'timestep': 1.0,\n",
        "        'imputation': 'previous',\n",
        "        'normalizer_state': None}\n",
        "print('Result of best_classifier')        \n",
        "metrics_results, pred_probs, y_true = test(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0B1k-sXrzNBy",
      "metadata": {
        "id": "0B1k-sXrzNBy"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Edqs2iYrzNBy",
      "metadata": {
        "id": "Edqs2iYrzNBy"
      },
      "outputs": [],
      "source": [
        "# Figures ROC and calibration curve\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "import matplotlib.transforms as mtransforms\n",
        "import pickle\n",
        "from sklearn import metrics\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gmpE4mhkzNB0",
      "metadata": {
        "id": "gmpE4mhkzNB0"
      },
      "outputs": [],
      "source": [
        "# roc curve\n",
        "lstm_fpr, lstm_tpr, lstm_thresholds = metrics.roc_curve(y_true, pred_probs)\n",
        "\n",
        "# plot the roc curve for the model\n",
        "plt.figure()\n",
        "plt.ylim(0., 1.0)\n",
        "plt.xlim(0.,1.0)\n",
        "plt.plot(lstm_fpr, lstm_tpr, marker='.', label='LSTM_feat', color='darkorange')\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vbLKd8xgzNB0",
      "metadata": {
        "id": "vbLKd8xgzNB0"
      },
      "outputs": [],
      "source": [
        "# pr curve\n",
        "lstm_precision, lstm_recall, _ = metrics.precision_recall_curve(y_true, pred_probs)\n",
        "\n",
        "# plot the precision-recall curves\n",
        "plt.plot([0, 1], [1, 0], linestyle='--', label='No Skill')\n",
        "plt.plot(lstm_recall, lstm_precision, marker='.', label='LSTM_feat')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IhvDzqwRzNB0",
      "metadata": {
        "id": "IhvDzqwRzNB0"
      },
      "outputs": [],
      "source": [
        "# calibration curve\n",
        "lstm_y, lstm_x = calibration_curve(y_true, pred_probs, n_bins=10)\n",
        "plt.figure()\n",
        "plt.ylim(0., 1.0)\n",
        "plt.xlim(0.,1.0)\n",
        "plt.plot(lstm_x,lstm_y, marker='^', linestyle=\"\", markersize=7, label='LSTM_feat', color='darkorange')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "\n",
        "plt.xlabel('Mean predicted value')\n",
        "plt.ylabel('Fraction of positives')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LSTM_features.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
